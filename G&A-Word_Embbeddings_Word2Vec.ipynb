{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"G&A-Word_Embbeddings_Word2Vec.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"metadata":{"id":"f9Gstwuep1Mi","colab_type":"text"},"cell_type":"markdown","source":["# Session 13: Word Embeddings using the Word2Vec skip-gram model\n","\n","------------------------------------------------------\n","*Machine Learning, Master in Big Data Analytics, 2017-2018*\n","\n","*Pablo M. Olmos olmos@tsc.uc3m.es*\n","\n","------------------------------------------------------\n","The goal of this assignment is to train a Word2Vec skip-gram model over a data base of plain tex [Text8](http://mattmahoney.net/dc/textdata).\n","\n","This is a personal wrap-up of all the material provided by [Google's Deep Learning course on Udacity](https://www.udacity.com/course/deep-learning--ud730), so all credit goes to them. \n"]},{"metadata":{"id":"JL7ln3n3p1Mk","colab_type":"text"},"cell_type":"markdown","source":["The following [link](http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/) gives a very simple explanation of the model. Check also the following video."]},{"metadata":{"id":"A25TCIxRTyvR","colab_type":"text"},"cell_type":"markdown","source":["**ALPER KOCABIYIK & GONZALO ALVAREZ**"]},{"metadata":{"id":"TDbROZM_p1Ml","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":321},"outputId":"908dbd1f-1bf3-4862-fe21-7d03d4ca0e11","executionInfo":{"status":"ok","timestamp":1527161226337,"user_tz":-120,"elapsed":1247,"user":{"displayName":"ALPER KOCABIYIK","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"102273273575385653417"}}},"cell_type":"code","source":["from IPython.display import YouTubeVideo\n","\n","YouTubeVideo('xMwx2A_o5r4')   "],"execution_count":1,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","        <iframe\n","            width=\"400\"\n","            height=\"300\"\n","            src=\"https://www.youtube.com/embed/xMwx2A_o5r4\"\n","            frameborder=\"0\"\n","            allowfullscreen\n","        ></iframe>\n","        "],"text/plain":["<IPython.lib.display.YouTubeVideo at 0x7f9cc40c7978>"],"image/jpeg":"/9j/4AAQSkZJRgABAQAAAQABAAD/2wCEABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkz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\nAAAAAAAAAAAAAAAAAAAAAAAAAAB//9k=\n"},"metadata":{"tags":[]},"execution_count":1}]},{"metadata":{"id":"vA5Acqe0p1Mt","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# These are all the modules we'll be using later. Make sure you can import them\n","# before proceeding further.\n","%matplotlib inline\n","from __future__ import print_function\n","import collections\n","import math\n","import numpy as np\n","import os\n","import random\n","import tensorflow as tf\n","import zipfile\n","from matplotlib import pylab\n","from six.moves import range\n","from six.moves.urllib.request import urlretrieve\n","from sklearn.manifold import TSNE\n","\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"GZwYUSpPp1Mw","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":34},"outputId":"600d352e-ee58-4f7f-9768-cff0bb432eb6","executionInfo":{"status":"ok","timestamp":1527161230053,"user_tz":-120,"elapsed":553,"user":{"displayName":"ALPER KOCABIYIK","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"102273273575385653417"}}},"cell_type":"code","source":["# Lets check what version of tensorflow we have installed. The provided scripts should run with tf 1.0 and above\n","\n","print(tf.__version__)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["1.8.0\n"],"name":"stdout"}]},{"metadata":{"id":"sYek9JvTdJtt","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":37},"outputId":"5e866c04-5532-4c8e-f082-69c3bb8eefdf","executionInfo":{"status":"ok","timestamp":1527161262316,"user_tz":-120,"elapsed":32036,"user":{"displayName":"ALPER KOCABIYIK","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"102273273575385653417"}}},"cell_type":"code","source":["from google.colab import files\n","uploaded = files.upload()"],"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-87764f07-bb62-4b07-b810-b91849159ed4\" name=\"files[]\" multiple disabled />\n","     <output id=\"result-87764f07-bb62-4b07-b810-b91849159ed4\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"metadata":{"id":"DJY-riDrp1M0","colab_type":"text"},"cell_type":"markdown","source":["We will use the plain text database from this [link](http://mattmahoney.net/dc/textdata.html)"]},{"metadata":{"id":"wLd0rDXrioM5","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":338},"outputId":"0c119844-f069-4ac8-c432-17d7bcba00ba","executionInfo":{"status":"error","timestamp":1527161263208,"user_tz":-120,"elapsed":836,"user":{"displayName":"ALPER KOCABIYIK","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"102273273575385653417"}}},"cell_type":"code","source":["filename = './text8.zip'\n","#Here I provide some text preprocessing functions\n","import preprocessing"],"execution_count":5,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-a6b6be179c5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./text8.zip'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#Here I provide some text preprocessing functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'preprocessing'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}]},{"metadata":{"id":"BJMcRLurp1M4","colab_type":"text"},"cell_type":"markdown","source":["Read the data into a string"]},{"metadata":{"id":"CrK1mB70p1M4","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":185},"outputId":"f4ec489b-ad59-4d9a-c242-77f693551c77","executionInfo":{"status":"error","timestamp":1526902100924,"user_tz":-120,"elapsed":624,"user":{"displayName":"ALPER KOCABIYIK","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"102273273575385653417"}}},"cell_type":"code","source":["words = preprocessing.read_data(filename)\n","print('Data size %d' % len(words))"],"execution_count":38,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-38-b732b0866b4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Data size %d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: module 'preprocessing' has no attribute 'read_data'"]}]},{"metadata":{"id":"whWuQh9hp1M9","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":167},"outputId":"6bb4c0af-5c14-4cff-e380-e3af73a144d7","executionInfo":{"status":"error","timestamp":1526896713406,"user_tz":-120,"elapsed":631,"user":{"displayName":"ALPER KOCABIYIK","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"102273273575385653417"}}},"cell_type":"code","source":["type(words)"],"execution_count":27,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-27-d063f5800fac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'words' is not defined"]}]},{"metadata":{"id":"7SRj65gCp1NA","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":165},"outputId":"46647c04-0505-40c8-f6d4-a979337720df","executionInfo":{"status":"error","timestamp":1527067323414,"user_tz":-120,"elapsed":989,"user":{"displayName":"ALPER KOCABIYIK","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"102273273575385653417"}}},"cell_type":"code","source":["print(words[0:20])"],"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-ef89c7dc1655>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'words' is not defined"]}]},{"metadata":{"id":"hRFIz_Nlp1NE","colab_type":"text"},"cell_type":"markdown","source":["Build the dictionary and replace rare unfrequent words with UNK token. "]},{"metadata":{"id":"9wABq_adp1NE","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":234},"outputId":"91ec73a0-d3db-4835-b807-cd0a6e56aa12","executionInfo":{"status":"error","timestamp":1527067331045,"user_tz":-120,"elapsed":567,"user":{"displayName":"ALPER KOCABIYIK","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"102273273575385653417"}}},"cell_type":"code","source":["vocabulary_size = 50000\n","\n","data, count, dictionary, reverse_dictionary = preprocessing.build_dataset(vocabulary_size,words)\n","print('Most common words (+UNK)', count[:5])\n","print('Sample data', data[:10])\n","del words  # Hint to reduce memory use."],"execution_count":2,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-60be83c1e9f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mvocabulary_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse_dictionary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Most common words (+UNK)'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Sample data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'preprocessing' is not defined"]}]},{"metadata":{"id":"rjvDlK1yp1NK","colab_type":"text"},"cell_type":"markdown","source":["**Let**'s display the internal variables to better understand their structure:"]},{"metadata":{"id":"2MqQToKIp1NL","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":182},"outputId":"1bb4efec-a3af-4d28-a63b-1b7798676649","executionInfo":{"status":"error","timestamp":1527067334424,"user_tz":-120,"elapsed":628,"user":{"displayName":"ALPER KOCABIYIK","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"102273273575385653417"}}},"cell_type":"code","source":["print(data[:10])\n","print(count[:10])"],"execution_count":3,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-c031ba24464f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"]}]},{"metadata":{"id":"jP9D1gJSp1NP","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":182},"outputId":"74ff1d02-7d94-4cc4-ea40-be688a9cd0e3","executionInfo":{"status":"error","timestamp":1527067337199,"user_tz":-120,"elapsed":646,"user":{"displayName":"ALPER KOCABIYIK","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"102273273575385653417"}}},"cell_type":"code","source":["print(list(dictionary.items())[:10])\n","print(list(reverse_dictionary.items())[:10])"],"execution_count":4,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-cb1e437d1cc3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreverse_dictionary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'dictionary' is not defined"]}]},{"metadata":{"id":"oemhMTnfp1Na","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":182},"outputId":"663e487e-59b3-4e42-e216-6ce349a7b35c","executionInfo":{"status":"error","timestamp":1527067338188,"user_tz":-120,"elapsed":729,"user":{"displayName":"ALPER KOCABIYIK","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"102273273575385653417"}}},"cell_type":"code","source":["print('The index of the word \"crafty\" in dictionary is %d\\n' %(dictionary['crafty']))\n","print('The word corresponding to the index 875 is %s\\n' %(reverse_dictionary[875]))"],"execution_count":5,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-c3b49e03c3b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The index of the word \"crafty\" in dictionary is %d\\n'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'crafty'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The word corresponding to the index 875 is %s\\n'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreverse_dictionary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m875\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'dictionary' is not defined"]}]},{"metadata":{"id":"QRrhxYUcp1Nj","colab_type":"text"},"cell_type":"markdown","source":["## Generating training batches"]},{"metadata":{"id":"4Tq8ZY8yp1Nk","colab_type":"text"},"cell_type":"markdown","source":["The function 'preprocessing.generate_batch' generates training batchs for the skip-gram model.\n","\n","\n","<img src=\"Fig1.png\" width=\"600\" height=\"400\">\n","\n","Figure borrowed from this [post](http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/)."]},{"metadata":{"id":"qUfVjc08p1Nl","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":234},"outputId":"7fec5c7c-bd64-448b-b258-5157e89ebbf0","executionInfo":{"status":"error","timestamp":1527067340910,"user_tz":-120,"elapsed":559,"user":{"displayName":"ALPER KOCABIYIK","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"102273273575385653417"}}},"cell_type":"code","source":["data_index = 0\n","\n","\"\"\"Generate a batch of data for training.\n","    Args:\n","        batch_size: Number of samples to generate in the batch.\n","        \n","        skip_window:# How many words to consider left and right.\n","        \n","            How many words to consider around the target word, left and right.\n","            With skip_window=2, in the sentence above for \"consider\" we'll\n","            build the window [words, to, consider, around, the].\n","            \n","        num_skips: How many times to reuse an input to generate a label.\n","        \n","            For skip-gram, we map target word to adjacent words in the window\n","            around it. This parameter says how many adjacent word mappings to\n","            add to the batch for each target word. Naturally it can't be more\n","            than skip_window * 2.\n","            \n","    Returns:\n","        batch, labels - ndarrays with IDs.\n","        batch: Row vector of size batch_size containing target words.\n","        labels:\n","            Column vector of size batch_size containing a randomly selected\n","            adjacent word for every target word in 'batch'.\n","    \"\"\"\n","\n","\n","print('data:', [reverse_dictionary[di] for di in data[:32]])\n","\n","for num_skips, skip_window in [(2, 4)]:\n","    data_index = 0\n","    batch, labels = preprocessing.generate_batch(data, data_index, batch_size=16, num_skips=num_skips, skip_window=skip_window)\n","    print('\\nwith num_skips = %d and skip_window = %d:' % (num_skips, skip_window))\n","    print('    batch:', [reverse_dictionary[bi] for bi in batch])\n","    print('    labels:', [reverse_dictionary[li] for li in labels.reshape(16)])"],"execution_count":6,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-90edc0c23a91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mreverse_dictionary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnum_skips\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_window\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"]}]},{"metadata":{"id":"8KtT_fv-p1Nu","colab_type":"text"},"cell_type":"markdown","source":["## Using the above data set, now we train a skip-gram model!"]},{"metadata":{"id":"9RHhoIzTp1Nv","colab_type":"text"},"cell_type":"markdown","source":["The following [link](http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/) gives a very simple explanation of the model. The following figures are borrowed from that post.\n","\n","<img src=\"Fig2.png\" width=\"600\" height=\"400\">\n","\n","<img src=\"Fig3.png\" width=\"600\" height=\"400\">"]},{"metadata":{"id":"xhxIVgnSp1Nw","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":234},"outputId":"c68c6e4c-7db8-44ae-ba35-55cf18e4e0ad","executionInfo":{"status":"error","timestamp":1527067345196,"user_tz":-120,"elapsed":705,"user":{"displayName":"ALPER KOCABIYIK","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"102273273575385653417"}}},"cell_type":"code","source":["batch_size = 32\n","embedding_size = 128 # Dimension of the embedding vector.\n","skip_window = 1 # How many words to consider left and right.\n","num_skips = 2 # How many times to reuse an input to generate a label.\n","\n","# We pick a random validation set to sample nearest neighbors. here we limit the\n","# validation samples to the words that have a low numeric ID, which by\n","# construction are also the most frequent. \n","valid_size = 32 # Random set of words to evaluate similarity on.\n","valid_window = 200 # Only pick samples in the head of the distribution.\n","valid_examples = np.array(random.sample(range(valid_window), valid_size))\n","\n","num_sampled = 64 # Number of negative examples to sample.\n","\n","graph = tf.Graph()\n","\n","with graph.as_default(), tf.device('/cpu:0'):\n","\n","    # Input data.\n","    train_dataset = tf.placeholder(tf.int32, shape=[batch_size])\n","    train_labels = tf.placeholder(tf.int32, shape=[batch_size, 1])\n","    valid_dataset = tf.constant(valid_examples, dtype=tf.int32)\n","  \n","    # Variables.\n","    embeddings = tf.Variable(tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0))\n","    softmax_weights = tf.Variable(\n","        tf.truncated_normal([vocabulary_size, embedding_size],stddev=1.0 / math.sqrt(embedding_size)))\n","    softmax_biases = tf.Variable(tf.zeros([vocabulary_size]))\n","  \n","    # Model.\n","    # Look up embeddings for inputs. YOU DON'T NEED THE ONE HOT ENCODING FOR THE INPUT!!!! \n","    embed = tf.nn.embedding_lookup(embeddings, train_dataset)\n","    # Compute the softmax loss, using a sample of the negative labels each time.\n","    loss = tf.reduce_mean(tf.nn.sampled_softmax_loss(softmax_weights, softmax_biases, train_labels, \n","                                                     embed, num_sampled, vocabulary_size))\n","\n","    # Optimizer.\n","    optimizer = tf.train.AdagradOptimizer(1.0).minimize(loss)\n","  \n","    # Compute the similarity between minibatch examples and all embeddings.\n","    # We use the cosine distance:\n","    norm = tf.sqrt(tf.reduce_sum(tf.square(embeddings), 1, keep_dims=True))\n","    normalized_embeddings = embeddings / norm\n","    valid_embeddings = tf.nn.embedding_lookup(normalized_embeddings, valid_dataset)\n","    similarity = tf.matmul(valid_embeddings, tf.transpose(normalized_embeddings))"],"execution_count":7,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-57e864e7f965>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mvalid_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m \u001b[0;31m# Random set of words to evaluate similarity on.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mvalid_window\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;31m# Only pick samples in the head of the distribution.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mvalid_examples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_window\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mnum_sampled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m \u001b[0;31m# Number of negative examples to sample.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"]}]},{"metadata":{"id":"ZUSnsGfBp1N0","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":234},"outputId":"6431f851-a7eb-461d-b759-c6d42486d03d","executionInfo":{"status":"error","timestamp":1527067346828,"user_tz":-120,"elapsed":560,"user":{"displayName":"ALPER KOCABIYIK","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"102273273575385653417"}}},"cell_type":"code","source":["num_steps = 100001\n","data_index = 0\n","\n","with tf.Session(graph=graph) as session:\n","    tf.global_variables_initializer().run()\n","    print('Initialized')\n","    average_loss = 0\n","    for step in range(num_steps):\n","\n","        batch_data, batch_labels = preprocessing.generate_batch(data,data_index,batch_size, num_skips, skip_window) \n","        data_index = (data_index + batch_size) % len(data)\n","        \n","        feed_dict = {train_dataset : batch_data, train_labels : batch_labels}\n","        _, l = session.run([optimizer, loss], feed_dict=feed_dict)\n","        average_loss += l\n","        if step % 2000 == 0:\n","            if step > 0:\n","                average_loss = average_loss / 2000\n","            # The average loss is an estimate of the loss over the last 2000 batches.\n","            print('Average loss at step %d: %f' % (step, average_loss))\n","            average_loss = 0\n","            \n","        # note that this is expensive (~20% slowdown if computed every 500 steps)\n","        if step % 25000 == 0:\n","            sim = similarity.eval()\n","            for i in range(valid_size):\n","                valid_word = reverse_dictionary[valid_examples[i]]\n","                top_k = 8 # number of nearest neighbors\n","                nearest = (-sim[i, :]).argsort()[1:top_k+1]\n","                log = 'Nearest to %s:' % valid_word\n","                for k in range(top_k):\n","                    close_word = reverse_dictionary[nearest[k]]\n","                    log = '%s %s,' % (log, close_word)\n","                print(log)\n","    \n","    final_embeddings = normalized_embeddings.eval()"],"execution_count":8,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-01f0ff47c8bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdata_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Initialized'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"]}]},{"metadata":{"id":"t-r6Kjdyp1N4","colab_type":"text"},"cell_type":"markdown","source":["This is what an embedding looks like:"]},{"metadata":{"id":"CmbVo00op1N5","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":391},"outputId":"f9337243-bca2-4d5d-db2a-ecff73e1d8af","executionInfo":{"status":"ok","timestamp":1526568507077,"user_tz":-120,"elapsed":546,"user":{"displayName":"GULNUR DEMIR","photoUrl":"//lh5.googleusercontent.com/-9TJ3DCO7Is8/AAAAAAAAAAI/AAAAAAAAAAo/zurS3QuTzUo/s50-c-k-no/photo.jpg","userId":"103362058300950202292"}}},"cell_type":"code","source":["print(final_embeddings[2,:])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[-0.01284116  0.06370314  0.00942189 -0.01602132  0.07380902  0.04375131\n"," -0.00536275 -0.03986432  0.06196572  0.04728323 -0.06939422  0.05216813\n"," -0.07189895 -0.08680649  0.175111    0.02106102 -0.00929935 -0.06048186\n","  0.03464364 -0.00890897  0.01135485 -0.07787979 -0.15920529 -0.10795777\n"," -0.01461228  0.04387816  0.09124263  0.07794994  0.01704169 -0.06789587\n"," -0.04556559  0.08053475  0.04520644  0.04617961  0.11115272  0.06227123\n"," -0.1828819   0.00407876 -0.01251844  0.13607536  0.10897586  0.13243057\n"," -0.10650989  0.02228085 -0.10272355 -0.05798529 -0.05263516 -0.24128814\n"," -0.02581607 -0.07971399  0.1369812   0.0072524   0.11279783  0.10323644\n","  0.07777879 -0.04932854 -0.05365378 -0.05353532 -0.05135224 -0.00755685\n"," -0.00152384 -0.07725015  0.06679566 -0.11252768 -0.01926792 -0.0611034\n","  0.05149738 -0.07176072  0.20261957 -0.06835694 -0.03730052  0.14804047\n","  0.24404204  0.03069032  0.06768436 -0.05709276 -0.02484669  0.0457652\n","  0.07585476  0.0883823  -0.01695413  0.04753481 -0.017565    0.08686765\n","  0.11673797 -0.02888013 -0.0380138   0.09473038  0.11565051  0.14799531\n"," -0.07926293  0.00899512  0.17800373 -0.04073282 -0.00727146 -0.02177852\n","  0.08977486  0.00330468  0.0666444   0.15026706 -0.0648203   0.04682897\n","  0.03029084  0.09681517 -0.14522481 -0.03270465 -0.03999791 -0.13868994\n"," -0.00819584  0.01477077  0.04247269 -0.11241012 -0.01438451  0.0195897\n","  0.04772708 -0.02522091 -0.03940912 -0.06033719  0.20355567  0.02295518\n"," -0.20383024  0.1511425   0.07864224  0.1169662  -0.12680532 -0.08444306\n"," -0.15425304 -0.07138815]\n"],"name":"stdout"}]},{"metadata":{"id":"tkYtoDyop1N-","colab_type":"text"},"cell_type":"markdown","source":["The embeddings have unit norm!"]},{"metadata":{"id":"DwtunOxep1N-","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":165},"outputId":"0be4bd24-332d-492a-b223-1b55b223ab5d","executionInfo":{"status":"error","timestamp":1527067350212,"user_tz":-120,"elapsed":638,"user":{"displayName":"ALPER KOCABIYIK","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"102273273575385653417"}}},"cell_type":"code","source":["print(np.sum(np.square(final_embeddings[40000,:])))"],"execution_count":9,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-d159de6ed5f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_embeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m40000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"]}]},{"metadata":{"id":"BY6wqWiIp1OB","colab_type":"text"},"cell_type":"markdown","source":["Now we project the emmbeding vectors into a 2-dimensional space using [TSNE](https://lvdmaaten.github.io/publications/papers/JMLR_2008.pdf)\n","\n","We use the [TSNE sklearn implementation](https://lvdmaaten.github.io/publications/papers/JMLR_2008.pdf)"]},{"metadata":{"id":"Q8j-Vrdup1OC","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["num_points = 200\n","\n","tsne = TSNE(perplexity=30, n_components=2, init='pca', n_iter=500)\n","\n","two_d_embeddings = tsne.fit_transform(final_embeddings[1:num_points+1, :])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Crhg7RwVp1OE","colab_type":"text"},"cell_type":"markdown","source":["Lets visualize the result"]},{"metadata":{"id":"rBa1BqJCp1OF","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":217},"outputId":"9885ea50-ee3a-4a8e-a6f4-f966e387c90f","executionInfo":{"status":"error","timestamp":1527067352070,"user_tz":-120,"elapsed":560,"user":{"displayName":"ALPER KOCABIYIK","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"102273273575385653417"}}},"cell_type":"code","source":["def plot(embeddings, labels):\n","    print(labels)\n","    assert embeddings.shape[0] >= len(labels), 'More labels than embeddings'\n","    pylab.figure(figsize=(15,15))  # in inches\n","    print(embeddings.shape)\n","    for i, label in enumerate(labels):\n","        x, y = embeddings[i,:]\n","        pylab.scatter(x, y)\n","        pylab.annotate(label, xy=(x, y), xytext=(5, 2), textcoords='offset points',ha='right', va='bottom')\n","    pylab.show()\n","\n","words = [reverse_dictionary[i] for i in range(1, num_points+1)]\n","plot(two_d_embeddings, words)"],"execution_count":10,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-b1d3fafb9b0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mpylab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mreverse_dictionary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_points\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtwo_d_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'num_points' is not defined"]}]},{"metadata":{"id":"fC6W2NTlp1OI","colab_type":"text"},"cell_type":"markdown","source":["## Problem 4\n","\n","1) Evaluate the efect of the number of negative samples used for the sampled soft max loss.\n","\n","2) In the original [wor2vec paper](https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf) the authors showed an striking discovery: word analogy tasks can be solved by simple linear algebra. For example, the word analogy question **man-->woman-->king-->??** can be solved by looking for the embedding word $v_w$ such that $v_{\\text{king}}-v_{w}$ is most similar to $v_{\\text{man}}v_{\\text{woman}}$; in other words, minimizes \n","\\begin{align}\n","||v_{w}-v_{\\text{king}}+v_{\\text{man}}v_{\\text{woman}}||^2\n","\\end{align}\n","\n","Note that, in case the above norm is zero, this means that \n","\\begin{align}\n","v_{w} = v_{\\text{king}}-v_{\\text{man}}+v_{\\text{woman}}\n","\\end{align}\n","\n","Try to study this effect in the set of word embeddings you just computed. Recall you can check the list of words in the list 'count'. **Note:** most likely it won't work, since we have used a very small database. But it will be fun to think about semantic operations in an embedding space though!"]},{"metadata":{"id":"uWOsA6visLLX","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":234},"outputId":"8166c5bd-aa3b-4dea-b889-452ad9f61dd9","executionInfo":{"status":"error","timestamp":1527067355877,"user_tz":-120,"elapsed":616,"user":{"displayName":"ALPER KOCABIYIK","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"102273273575385653417"}}},"cell_type":"code","source":["# 1.1)\n","\n","def define_embed_graph(num_sampled):\n","\n","  graph = tf.Graph()\n","\n","  with graph.as_default(), tf.device('/cpu:0'):\n","    # Input data.\n","    train_dataset = tf.placeholder(tf.int32, shape=[batch_size])\n","    train_labels = tf.placeholder(tf.int32, shape=[batch_size, 1])\n","    valid_dataset = tf.constant(valid_examples, dtype=tf.int32)\n","  \n","    # Variables.\n","    embeddings = tf.Variable(tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0))\n","    softmax_weights = tf.Variable(\n","        tf.truncated_normal([vocabulary_size, embedding_size],stddev=1.0 / math.sqrt(embedding_size)))\n","    softmax_biases = tf.Variable(tf.zeros([vocabulary_size]))\n","  \n","    # Model.\n","    # Look up embeddings for inputs. YOU DON'T NEED THE ONE HOT ENCODING FOR THE INPUT!!!! \n","    embed = tf.nn.embedding_lookup(embeddings, train_dataset)\n","    # Compute the softmax loss, using a sample of the negative labels each time.\n","    loss = tf.reduce_mean(tf.nn.sampled_softmax_loss(softmax_weights, softmax_biases, train_labels, \n","                                                     embed, num_sampled, vocabulary_size))\n","\n","    # Optimizer.\n","    optimizer = tf.train.AdagradOptimizer(1.0).minimize(loss)\n","  \n","    # Compute the similarity between minibatch examples and all embeddings.\n","    # We use the cosine distance:\n","    norm = tf.sqrt(tf.reduce_sum(tf.square(embeddings), 1, keep_dims=True))\n","    normalized_embeddings = embeddings / norm\n","    valid_embeddings = tf.nn.embedding_lookup(normalized_embeddings, valid_dataset)\n","    similarity = tf.matmul(valid_embeddings, tf.transpose(normalized_embeddings))\n","  \n","  \n","def run_graph(num_steps):\n","  \n","  data_index = 0\n","\n","  with tf.Session(graph=graph) as session:\n","    tf.global_variables_initializer().run()\n","    print('Initialized')\n","    average_loss = 0\n","    for step in range(num_steps):\n","\n","      batch_data, batch_labels = preprocessing.generate_batch(data,data_index,batch_size, num_skips, skip_window) \n","      data_index = (data_index + batch_size) % len(data)\n","        \n","      feed_dict = {train_dataset : batch_data, train_labels : batch_labels}\n","      _, l = session.run([optimizer, loss], feed_dict=feed_dict)\n","      average_loss += l\n","      if step % 2000 == 0:\n","        if step > 0:\n","          avg_loss = average_loss / 2000\n","          average_loss = 0\n","    final_embeddings = normalized_embeddings.eval()\n","    return avg_loss\n","  \n","  \n","num_negative_arr = [16, 32, 64, 128, 256, 512]\n","avg_loss = np.zeros(len(num_negative_arr))\n","\n","for i in range(len(num_negative_arr)):\n","  batch_size = 32\n","  embedding_size = 128 \n","  skip_window = 1 \n","  num_skips = 2 \n","  valid_size = 32 \n","  valid_window = 200 \n","  valid_examples = np.array(random.sample(range(valid_window), valid_size))\n","  num_steps = 100001\n","  \n","  # define and run graph with 'num_negative_arr' number of negative samples\n","  define_embed_graph(num_negative_arr[i])\n","  avg_loss[i] = run_graph(num_steps)\n","  print ('Average loss with %d negative samples is %r' %(num_negative_arr[i], avg_loss[i]))\n"],"execution_count":11,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-3272d8535734>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0mnum_negative_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_negative_arr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_negative_arr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"]}]},{"metadata":{"id":"0p5P4YoO1-nl","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":217},"outputId":"2950c2c5-ffae-4328-a95e-e0782dd8a182","executionInfo":{"status":"error","timestamp":1527067357945,"user_tz":-120,"elapsed":581,"user":{"displayName":"ALPER KOCABIYIK","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"102273273575385653417"}}},"cell_type":"code","source":["# 1.2)\n","\n","import matplotlib.pyplot as plt\n","\n","plt.figure()\n","plt.plot(num_negative_arr, avg_loss)"],"execution_count":12,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-31efed104851>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_negative_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'avg_loss' is not defined"]},{"output_type":"display_data","data":{"text/plain":["<matplotlib.figure.Figure at 0x7f22c6cab908>"]},"metadata":{"tags":[]}}]},{"metadata":{"id":"Dq_8YP2-p1OJ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":356},"outputId":"aae3b542-ed90-4742-cbfd-26c4f977082e","executionInfo":{"status":"error","timestamp":1527067359335,"user_tz":-120,"elapsed":746,"user":{"displayName":"ALPER KOCABIYIK","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"102273273575385653417"}}},"cell_type":"code","source":["words = [reverse_dictionary[i] for i in range(0, 50000)]\n","\n","word1 = final_embeddings[[i for i in range(len(words)) if 'one'==words[i]][0],:] \n","word2 = final_embeddings[[i for i in range(len(words)) if 'three'==words[i]][0],:]\n","\n","word1_1 = final_embeddings[[i for i in range(len(words)) if 'english'==words[i]][0],:] \n","word2_1 = final_embeddings[[i for i in range(len(words)) if 'country'==words[i]][0],:]\n","word3_1 = final_embeddings[[i for i in range(len(words)) if 'language'==words[i]][0],:]\n","\n","word1_2 = final_embeddings[[i for i in range(len(words)) if 'absolutist'==words[i]][0],:] \n","word2_2 = final_embeddings[[i for i in range(len(words)) if 'king'==words[i]][0],:]\n","word3_2 = final_embeddings[[i for i in range(len(words)) if 'government'==words[i]][0],:]\n","\n","first_try = word1 + word2 #four in the third position\n","second_try = word1_1 + word2_1 - word3_1\n","third_try =  - word1_2 + word2_2 + word3_2#president in the third position\n","\n","\n","def closest_node(node, nodes):\n","    nodes = np.asarray(nodes)\n","    deltas = nodes - node\n","    dist_2 = np.linalg.norm(deltas, axis=1,ord=2)\n","    d_1 =np.argsort(dist_2)\n","    for i in range(15):\n","       print(reverse_dictionary[d_1[i]])\n","    return d_1\n","\n","_ = closest_node(third_try,final_embeddings)"],"execution_count":13,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-a90cfe18054d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mreverse_dictionary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mword1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_embeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'one'\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mword2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_embeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'three'\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-13-a90cfe18054d>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mreverse_dictionary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mword1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_embeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'one'\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mword2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_embeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'three'\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'reverse_dictionary' is not defined"]}]}]}